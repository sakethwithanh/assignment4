{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8173355,"sourceType":"datasetVersion","datasetId":4837652},{"sourceId":8194534,"sourceType":"datasetVersion","datasetId":4853543}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-04T12:25:09.603349Z","iopub.execute_input":"2024-05-04T12:25:09.603771Z","iopub.status.idle":"2024-05-04T12:25:09.609265Z","shell.execute_reply.started":"2024-05-04T12:25:09.603739Z","shell.execute_reply":"2024-05-04T12:25:09.608166Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:09.610912Z","iopub.execute_input":"2024-05-04T12:25:09.611281Z","iopub.status.idle":"2024-05-04T12:25:09.623556Z","shell.execute_reply.started":"2024-05-04T12:25:09.611246Z","shell.execute_reply":"2024-05-04T12:25:09.622704Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/assignment-4/Reviews.csv')\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:09.625289Z","iopub.execute_input":"2024-05-04T12:25:09.625546Z","iopub.status.idle":"2024-05-04T12:25:12.681649Z","shell.execute_reply.started":"2024-05-04T12:25:09.625523Z","shell.execute_reply":"2024-05-04T12:25:12.680621Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 568454 entries, 0 to 568453\nData columns (total 3 columns):\n #   Column      Non-Null Count   Dtype \n---  ------      --------------   ----- \n 0   Unnamed: 0  568454 non-null  int64 \n 1   Summary     568427 non-null  object\n 2   Text        568454 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 13.0+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndf.dropna(inplace=True)  \n\ndf['Text'] = df['Text'].apply(lambda x: ' '.join(x.split()[:98]))\n\ndf['training'] = df['Text'] + ' TL;DR ' + df['Summary']\ndf_train=df[['Summary','Text','training']][:75]\ndf_test= df[['Summary','Text','training']][75:100]\n\ndf=df_train","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:12.683090Z","iopub.execute_input":"2024-05-04T12:25:12.683505Z","iopub.status.idle":"2024-05-04T12:25:18.325310Z","shell.execute_reply.started":"2024-05-04T12:25:12.683468Z","shell.execute_reply":"2024-05-04T12:25:18.324477Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"max_length = 100\ndf[\"training\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:18.331744Z","iopub.execute_input":"2024-05-04T12:25:18.332015Z","iopub.status.idle":"2024-05-04T12:25:18.338324Z","shell.execute_reply.started":"2024-05-04T12:25:18.331992Z","shell.execute_reply":"2024-05-04T12:25:18.337337Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than most. TL;DR Good Quality Dog Food'"},"metadata":{}}]},{"cell_type":"code","source":"\n\ndef preprocess_text(text):\n\n    text = text.lower()\n\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n    stop_words = stopwords.words('english')\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    stemmer = PorterStemmer()\n    text = ' '.join([stemmer.stem(word) for word in text.split()])\n\n    return text\n\npreprocess_text(df[\"training\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:18.339518Z","iopub.execute_input":"2024-05-04T12:25:18.339852Z","iopub.status.idle":"2024-05-04T12:25:18.355292Z","shell.execute_reply.started":"2024-05-04T12:25:18.339817Z","shell.execute_reply":"2024-05-04T12:25:18.354405Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better tldr good qualiti dog food'"},"metadata":{}}]},{"cell_type":"code","source":"\n \nclass GPT2ReviewDataset(Dataset):  \n    def __init__(self, tokenizer, reviews, max_len):\n        self.max_length = max_len\n        self.tokenizer = tokenizer\n        self.eos = self.tokenizer.eos_token\n        self.end_token_id = self.tokenizer.eos_token_id\n        self.reviews = reviews\n        self.result = []\n\n        for review in self.reviews:\n            \n            k=preprocess_text(review).split()\n            idx = k.index('tldr')\n            k[idx] = ' TL;DR '\n            if(len(k)>115):\n                k=k[:114]\n                k=\" \".join(k)\n            else:\n                d=len(k)\n                k=\" \".join(k)\n                for i in range(114-d):\n                    k+=\"<|endoftext|>\"\n#             print(len(k.split()))\n            tokenized = self.tokenizer.encode(k + \"<|endoftext|>\")\n#             print(len(tokenized))\n#             break\n            tokenized = self.pad_truncate(tokenized)   \n            self.result.append(torch.tensor(tokenized))\n\n    def __len__(self):\n        return len(self.result)\n\n\n    def __getitem__(self, item):\n        return self.result[item]\n\n    def pad_truncate(self, encoded_text):\n        padding_length = 4\n        text_length = len(encoded_text) - padding_length\n        if text_length < self.max_length:\n            padding = [self.end_token_id] * (self.max_length - text_length)\n            return encoded_text + padding\n        elif text_length > self.max_length:\n            return encoded_text[:self.max_length + 3] + [self.end_token_id]\n        else:\n            return encoded_text\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:18.356353Z","iopub.execute_input":"2024-05-04T12:25:18.356654Z","iopub.status.idle":"2024-05-04T12:25:18.367632Z","shell.execute_reply.started":"2024-05-04T12:25:18.356630Z","shell.execute_reply":"2024-05-04T12:25:18.366772Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:18.368762Z","iopub.execute_input":"2024-05-04T12:25:18.369089Z","iopub.status.idle":"2024-05-04T12:25:19.232687Z","shell.execute_reply.started":"2024-05-04T12:25:18.369059Z","shell.execute_reply":"2024-05-04T12:25:19.231856Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"reviews_dataset = GPT2ReviewDataset(tokenizer, df['training'], 120)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:19.233939Z","iopub.execute_input":"2024-05-04T12:25:19.234235Z","iopub.status.idle":"2024-05-04T12:25:19.534340Z","shell.execute_reply.started":"2024-05-04T12:25:19.234210Z","shell.execute_reply":"2024-05-04T12:25:19.533253Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# len(reviews_dataset[100])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:19.538528Z","iopub.execute_input":"2024-05-04T12:25:19.538826Z","iopub.status.idle":"2024-05-04T12:25:19.543495Z","shell.execute_reply.started":"2024-05-04T12:25:19.538801Z","shell.execute_reply":"2024-05-04T12:25:19.542354Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# print(tokenizer.decode(reviews_dataset[0]))\n# print(df['training'][2])\nprint(reviews_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:19.544938Z","iopub.execute_input":"2024-05-04T12:25:19.545247Z","iopub.status.idle":"2024-05-04T12:25:19.556431Z","shell.execute_reply.started":"2024-05-04T12:25:19.545204Z","shell.execute_reply":"2024-05-04T12:25:19.555516Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"tensor([   65,  2917,  1750,  9204,   460,  3290,  2057,  1720,  1043,   922,\n         4140,  8846,  1720,   804,   588, 20798,  1429,  6174,  8508,  1365,\n         2248, 40368,   957,   624,    72,  5763,  1720,  1365,   220, 24811,\n           26,  7707,   220,   922,  4140,  8846,  3290,  2057, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n        50256, 50256, 50256, 50256])\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = DataLoader(reviews_dataset, batch_size=32, shuffle=True, drop_last= True)\ndef train(model, optimizer, dl, epochs):    \n    for epoch in range(epochs):\n        for idx, batch in enumerate(dl):\n             with torch.set_grad_enabled(True):\n                optimizer.zero_grad()\n                batch = batch.to(device)\n                output = model(batch, labels=batch)\n                loss = output[0]\n                loss.backward()\n                optimizer.step()\n                if idx % 100 == 0:\n                    print(\"Loss is : %f \"%(loss))\n                    \noptimizer = torch.optim.AdamW(params = model.parameters(), lr=5e-5)\nmode=model.to(device)\nepoch=10\n                    \ntrain(model,optimizer, dataloader, epoch )","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:19.557579Z","iopub.execute_input":"2024-05-04T12:25:19.557860Z","iopub.status.idle":"2024-05-04T12:25:29.874207Z","shell.execute_reply.started":"2024-05-04T12:25:19.557836Z","shell.execute_reply":"2024-05-04T12:25:29.873156Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Loss is : 11.484254 \nLoss is : 4.203943 \nLoss is : 2.575060 \nLoss is : 2.503411 \nLoss is : 2.430969 \nLoss is : 2.398445 \nLoss is : 2.348293 \nLoss is : 2.508475 \nLoss is : 2.511341 \nLoss is : 2.222166 \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\npath = \"model.pt\"  \n\ntorch.save(model.state_dict(), path)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:29.875896Z","iopub.execute_input":"2024-05-04T12:25:29.876321Z","iopub.status.idle":"2024-05-04T12:25:31.094174Z","shell.execute_reply.started":"2024-05-04T12:25:29.876287Z","shell.execute_reply":"2024-05-04T12:25:31.093269Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"\n\npath = \"/kaggle/working/model.pt\"  \nloaded_model = torch.load(path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:31.095352Z","iopub.execute_input":"2024-05-04T12:25:31.095608Z","iopub.status.idle":"2024-05-04T12:25:31.376525Z","shell.execute_reply.started":"2024-05-04T12:25:31.095585Z","shell.execute_reply":"2024-05-04T12:25:31.375529Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n\ndef sample_next_word(probabilities):\n    probabilities = torch.softmax(probabilities, dim=-1)\n    normalized_probs = probabilities / torch.sum(probabilities)\n    return np.random.choice(len(probabilities), 1, p=normalized_probs.cpu().detach().numpy())[0]\n\n\ndef model_infer(model, tokenizer, review, max_length=15):\n    encoded_review = tokenizer.encode(review)\n    generated_sequence = encoded_review.copy()\n    initial_input = torch.tensor(generated_sequence).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        output = model(initial_input)\n        last_logits = output.logits[0, -1]\n        generated_sequence.append(sample_next_word(last_logits))\n\n        for _ in range(max_length - 1):\n            input_ids = torch.tensor(generated_sequence).unsqueeze(0).to(device)\n            output = model(input_ids)\n            last_logits = output.logits[0, -1]\n            next_word_id = sample_next_word(last_logits)\n\n            if next_word_id == tokenizer.eos_token_id:\n                break\n            else:\n                generated_sequence.append(next_word_id)\n\n    return tokenizer.decode(generated_sequence)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:31.377797Z","iopub.execute_input":"2024-05-04T12:25:31.378720Z","iopub.status.idle":"2024-05-04T12:25:31.388147Z","shell.execute_reply.started":"2024-05-04T12:25:31.378691Z","shell.execute_reply":"2024-05-04T12:25:31.387284Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"k=[\"I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. TL;DR Good Quality Dog Food\", \"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as Jumbo. TL;DR Not as Advertised\"]\nsamples = [review.split('TL;DR')[0] for review in k]\n    \nfor review in samples:\n\n    summary = model_infer(model, tokenizer, review + \" TL;DR \").split(\" TL;DR \")[1].strip()\n\n    print(\"Summaries: \"+ str(summary) +\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:26:41.555142Z","iopub.execute_input":"2024-05-04T12:26:41.555540Z","iopub.status.idle":"2024-05-04T12:26:41.743344Z","shell.execute_reply.started":"2024-05-04T12:26:41.555511Z","shell.execute_reply":"2024-05-04T12:26:41.742173Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Summaries: will present with good dog good deck will enjoy any dog\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_summaries=df_test['Summary'].values\ntest_text=df_test['Text'].values\ngenerated_summaries = []\nfor i in range(len(test_text)):\n    summry= model_infer(model, tokenizer, test_text[i] + \" TL;DR \").split(\" TL;DR \")[1].strip()\n    generated_summaries.append(summry)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:31.678513Z","iopub.execute_input":"2024-05-04T12:25:31.679209Z","iopub.status.idle":"2024-05-04T12:25:34.156814Z","shell.execute_reply.started":"2024-05-04T12:25:31.679171Z","shell.execute_reply":"2024-05-04T12:25:34.155961Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(test_summaries[i])\n    print(generated_summaries[i])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:34.158017Z","iopub.execute_input":"2024-05-04T12:25:34.158329Z","iopub.status.idle":"2024-05-04T12:25:34.164060Z","shell.execute_reply.started":"2024-05-04T12:25:34.158303Z","shell.execute_reply":"2024-05-04T12:25:34.163139Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"No Tea Flavor\nnice worth every second wasted\nGood\n--------------------\nTaste great\n1.5/\nOrder only in cold weather\n<|endoftext|>\nthis is the best\nrye cream with find  lemoni cant t put over coat blown over coat\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install rouge_score\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:34.165498Z","iopub.execute_input":"2024-05-04T12:25:34.166406Z","iopub.status.idle":"2024-05-04T12:25:49.752463Z","shell.execute_reply.started":"2024-05-04T12:25:34.166369Z","shell.execute_reply":"2024-05-04T12:25:49.751311Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=4c216144cd590e4e4ec1b20360e02d42387451c4f49f9e16a8399bc0fed4575f\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:25:49.754496Z","iopub.execute_input":"2024-05-04T12:25:49.755362Z","iopub.status.idle":"2024-05-04T12:26:02.471105Z","shell.execute_reply.started":"2024-05-04T12:25:49.755318Z","shell.execute_reply":"2024-05-04T12:26:02.469679Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\nrough_1=[]\nrough_2=[]\nrough_l=[]\nrouge_1_precisions = []\nrouge_1_recalls = []\nrouge_1_f1_scores = []\nrouge_2_precisions = []\nrouge_2_recalls = []\nrouge_2_f1_scores = []\nrouge_l_precisions = []\nrouge_l_recalls = []\nrouge_l_f1_scores = []\n\nscorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL'], use_stemmer=True)\nfor i in range(len(test_summaries)):\n    scores = scorer.score(test_summaries[i], generated_summaries[i])\n    rouge_1_precisions.append(scores['rouge1'][0])\n    rouge_1_recalls.append(scores['rouge1'][1])\n    rouge_1_f1_scores.append(scores['rouge1'][2])\n    \n    rouge_2_precisions.append(scores['rouge2'][0])\n    rouge_2_recalls.append(scores['rouge2'][1])\n    rouge_2_f1_scores.append(scores['rouge2'][2])\n    \n    rouge_l_precisions.append(scores['rougeL'][0])\n    rouge_l_recalls.append(scores['rougeL'][1])\n    rouge_l_f1_scores.append(scores['rougeL'][2])\n    \n    \n    \nrouge_1_precision_mean = sum(rouge_1_precisions) / len(rouge_1_precisions)\nrouge_1_recall_mean = sum(rouge_1_recalls) / len(rouge_1_recalls)\nrouge_1_f1_score_mean = sum(rouge_1_f1_scores) / len(rouge_1_f1_scores)\n\nrouge_2_precision_mean = sum(rouge_2_precisions) / len(rouge_2_precisions)\nrouge_2_recall_mean = sum(rouge_2_recalls) / len(rouge_2_recalls)\nrouge_2_f1_score_mean = sum(rouge_2_f1_scores) / len(rouge_2_f1_scores)\n\nrouge_l_precision_mean = sum(rouge_l_precisions) / len(rouge_l_precisions)\nrouge_l_recall_mean = sum(rouge_l_recalls) / len(rouge_l_recalls)\nrouge_l_f1_score_mean = sum(rouge_l_f1_scores) / len(rouge_l_f1_scores)\n\nprint(\"ROUGE-1: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(rouge_1_precision_mean, rouge_1_recall_mean, rouge_1_f1_score_mean))\nprint(\"ROUGE-2: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(rouge_2_precision_mean, rouge_2_recall_mean, rouge_2_f1_score_mean))\nprint(\"ROUGE-L: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(rouge_l_precision_mean, rouge_l_recall_mean, rouge_l_f1_score_mean))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:26:02.473584Z","iopub.execute_input":"2024-05-04T12:26:02.473910Z","iopub.status.idle":"2024-05-04T12:26:02.504419Z","shell.execute_reply.started":"2024-05-04T12:26:02.473881Z","shell.execute_reply":"2024-05-04T12:26:02.503477Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"ROUGE-1: Precision: 0.07, Recall: 0.11, F1-Score: 0.08\nROUGE-2: Precision: 0.01, Recall: 0.01, F1-Score: 0.01\nROUGE-L: Precision: 0.06, Recall: 0.10, F1-Score: 0.07\n","output_type":"stream"}]}]}